{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## How to create a stochastic model for MNIST? (I.e., a model which can be used for MC-Dropout and Point Predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "  import uncertainty_wizard as uwiz\n",
    "except ModuleNotFoundError as e:\n",
    "  # Uncertainty wizard was not installed. Install it now (we're probably on colab)\n",
    "  !pip install uncertainty_wizard\n",
    "  import uncertainty_wizard as uwiz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 1: Downloading Preprocessing the data**\n",
    "\n",
    "This is the same that we would do on any regular keras mnist classifier,\n",
    "except that we do not have to one-hot encode the test labels, as uncertainty wizards quantifiers\n",
    "will determine the winning class (one not its one-hot encoding) for us"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = (x_train.astype('float32') / 255).reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = (x_test.astype('float32') / 255).reshape(x_test.shape[0], 28, 28, 1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 2: Creating a Stochastic Uncertainty-Wizard Model using the Sequential API**\n",
    "\n",
    "Note that only the first line is different from doing the same in plain keras, the rest is equivalent.\n",
    "We must however ensure to use at least one randomized layer (e.g. tf.keras.layers.Dropout)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's create an uncertainty wizard model!\n",
    "#   We want to use a dropout-based stochastic model using the functional interface\n",
    "\n",
    "model = uwiz.models.StochasticSequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In the functional interface, we can add the layer as if we were working\n",
    "#   on a regular tf.keras.model.Sequential() using add()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Because we are building a stochastic model, we have to include at last one of the following keras layers\n",
    "#   tf.keras.layers.Dropout, tf.keras.layers.GaussionNoise, tf.keras.layers.GaussianDropout\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compiling and fitting is the same as in regular keras models as well:\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Note that we set the number of epochs to just 1, to be able to run this notebook quickly\n",
    "# Set the number of epochs higher if you want to optimally train the network.\n",
    "# Also note that obviously, with epochs=1, the currently passed callback does not do anything.\n",
    "model.fit(x_train, y_train, validation_split=0.1, batch_size=32, epochs=1,\n",
    "                  verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's print the summary of the inner model that is wrapped by the stochastic model we just created.\n",
    "#   Note that the Dropout-Layer was replaced by an UwizBernoulliDropout-Layer\n",
    "#   This allows the uncertainty wizard to control randomness during inference.\n",
    "print(model.inner.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 3: Make predictions and get the uncertainties and confidences**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-e5120d942dd1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mquantifiers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'pcs'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'mean_softmax'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m results = model.predict_quantified(x_test,\n\u001B[0m\u001B[1;32m      3\u001B[0m                                    \u001B[0mquantifier\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mquantifiers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                                    \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                                    \u001B[0msample_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "quantifiers = ['pcs', 'mean_softmax']\n",
    "results = model.predict_quantified(x_test,\n",
    "                                   quantifier=quantifiers,\n",
    "                                   batch_size=64,\n",
    "                                   sample_size=32,\n",
    "                                   verbose=1)\n",
    "\n",
    "# results[0][0] contains the point-predictions from the 'pcs' quantifier\n",
    "#     (i.e., argmax of a single non-randomized network forward pass)\n",
    "# results[0][1] contains the prediction confidence scores for these predictions\n",
    "\n",
    "# results[1][0] contains the predictions from the 'mean_softmax' quantifier\n",
    "#     (i.e., argmax of 32 averages forward pass samples on the randomized DNN)\n",
    "# results[1][1] contains the corresponding confidence\n",
    "#     (i.e., the average softmax value of the class with the highest average softmax value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}